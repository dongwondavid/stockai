import sqlite3
import polars as pl
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score
from pathlib import Path
from joblib import dump, load
import argparse
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import matplotlib.pyplot as plt
import seaborn as sns
import json
from datetime import datetime
import shap

# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.font_manager as fm

# Windowsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°
font_list = [f.name for f in fm.fontManager.ttflist]
korean_fonts = [f for f in font_list if 'Malgun' in f or 'ë§‘ì€' in f or 'Gulim' in f or 'êµ´ë¦¼' in f]

if korean_fonts:
    plt.rcParams['font.family'] = korean_fonts[0]
    print(f"í•œê¸€ í°íŠ¸ ì„¤ì •: {korean_fonts[0]}")
else:
    # í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì •
    plt.rcParams['font.family'] = 'DejaVu Sans'
    print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

plt.rcParams['axes.unicode_minus'] = False     # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ============================================================================
# ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬ - ì—¬ê¸°ì„œ True/Falseë¡œ ì‹¤í—˜ ì„¤ì •ì„ ë³€ê²½í•˜ì„¸ìš”
# ============================================================================
EXPERIMENT_CONFIG = {
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    'db_path': 'D:/db/solomon.db',
    'split_ratio': 0.5,  # ì• ì ˆë°˜ ë°ì´í„°ë¡œ í•™ìŠµ, ë’· ì ˆë°˜ìœ¼ë¡œ í‰ê°€
    
    # ëª¨ë¸ ì„¤ì •
    'use_smote': False,  # SMOTE ì‚¬ìš© ì—¬ë¶€
    'test_size': 0.2,    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ë¹„ìœ¨
    'random_state': 42,
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì„¤ì •
    'hyperparameter_optimization': {
        'enabled': False,  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‚¬ìš© ì—¬ë¶€
        'scoring': 'precision',  # ìµœì í™” ê¸°ì¤€: 'accuracy', 'precision', 'recall', 'f1', 'roc_auc'
        'cv_folds': 5,  # êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜
        'n_iter': 50,  # ëœë¤ ì„œì¹˜ ë°˜ë³µ íšŸìˆ˜
        'param_distributions': {
            'n_estimators': [50, 100, 200, 300],
            'max_depth': [5, 10, 15, 20, None],
            'min_samples_split': [2, 5, 10, 15],
            'min_samples_leaf': [1, 2, 4, 8],
            'max_features': ['sqrt', 'log2', None]
        }
    },
    
    # ëœë¤í¬ë ˆìŠ¤íŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ìµœì í™” ë¹„í™œì„±í™”ì‹œ ì‚¬ìš©)
    'n_estimators': 100,
    'max_depth': 10,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'class_weight': 'balanced',
    
    # ì‹¤í—˜í•  ëª¨ë¸ ì¡°í•©ë“¤ (Trueë¡œ ì„¤ì •ëœ ê²ƒë§Œ ì‹¤í–‰)
    'experiments': {
        'day1': False,
        'day2': False,
        'day3': False,
        'day4': False,
        'day1_day2_day3': False,
        'day1_day2_day3_day4': True
    },
    
    # í‰ê°€ ì„¤ì •
    'top_k': 1,  # í•˜ë£¨ì— ì„ íƒí•  ìƒìœ„ ì¢…ëª© ìˆ˜
    
    # íŠ¹ì„± ì„ íƒ (Trueë¡œ ì„¤ì •ëœ íŠ¹ì„±ë§Œ ì‚¬ìš©)
    'feature_selection': {
        'use_all_features': False,  # Falseë¡œ ì„¤ì •í•˜ì—¬ íŠ¹ì • íŠ¹ì„±ë§Œ ì‚¬ìš©
        'selected_features': [
            'day4_macd_histogram_increasing',
            'day4_short_macd_cross_signal',
            'day1_current_price_ratio',
            'day1_high_price_ratio',
            'day1_low_price_ratio',
            'day4_open_to_now_return',
            'day4_is_long_bull_candle',
            'day1_price_position_ratio',
            'day3_morning_mdd',
            'day1_fourth_derivative',
            'day1_long_candle_ratio',
            'day1_fifth_derivative',
            'day3_breaks_6month_high',
            'day2_prev_day_range_ratio',
            'day2_prev_close_to_now_ratio',
            'day4_macd_histogram',
            'day1_sixth_derivative',
            'day4_pos_vs_high_5d',
            'day4_rsi_value',
            'day4_pos_vs_high_3d'
        ]
    }
}

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def load_data_from_db(day_types, db_path, split_ratio=0.5, use_train_data=True):
    """
    SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§€ì •ëœ day í…Œì´ë¸”ë“¤ê³¼ answer í…Œì´ë¸”ì„ ì¡°ì¸í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    use_train_data: Trueë©´ ì• ì ˆë°˜(í•™ìŠµìš©), Falseë©´ ë’· ì ˆë°˜(í‰ê°€ìš©)
    """
    try:
        conn = sqlite3.connect(db_path)
        
        if isinstance(day_types, str):
            day_types = [day_types]
        
        # ë‹¨ì¼ í…Œì´ë¸”ì¸ ê²½ìš°
        if len(day_types) == 1:
            query = f"""
            SELECT d1.*, a.is_answer
            FROM {day_types[0]} d1
            INNER JOIN answer_v3 a ON CAST(REPLACE(d1.date, '-', '') AS INTEGER) = a.date 
                               AND d1.stock_code = a.stock_code
            WHERE a.date < 20230601
            ORDER BY d1.date, d1.stock_code
            """
        else:
            # ì—¬ëŸ¬ í…Œì´ë¸”ì¸ ê²½ìš° ì»¬ëŸ¼ëª…ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
            table_columns = {}
            for day_type in day_types:
                cursor = conn.cursor()
                cursor.execute(f"PRAGMA table_info({day_type})")
                columns = [row[1] for row in cursor.fetchall()]
                table_columns[day_type] = columns
            
            # SELECT ì ˆ êµ¬ì„± (ì¤‘ë³µ ì»¬ëŸ¼ ì œì™¸)
            select_parts = []
            used_columns = set()
            
            for i, day_type in enumerate(day_types):
                alias = f"d{i+1}"
                for col in table_columns[day_type]:
                    if col in ['date', 'stock_code']:
                        if col not in used_columns:
                            select_parts.append(f"{alias}.{col}")
                            used_columns.add(col)
                    else:
                        select_parts.append(f"{alias}.{col} AS {day_type}_{col}")
            
            select_clause = ", ".join(select_parts)
            
            # FROMê³¼ JOIN ì ˆ êµ¬ì„±
            from_clause = f"FROM {day_types[0]} d1"
            join_clause = ""
            
            for i, day_type in enumerate(day_types[1:], 2):
                join_clause += f" INNER JOIN {day_type} d{i} ON d1.date = d{i}.date AND d1.stock_code = d{i}.stock_code"
            
            query = f"""
            SELECT {select_clause}, a.is_answer
            {from_clause}
            {join_clause}
            INNER JOIN answer_v3 a ON CAST(REPLACE(d1.date, '-', '') AS INTEGER) = a.date 
                               AND d1.stock_code = a.stock_code
            WHERE a.date < 20230601
            ORDER BY d1.date, d1.stock_code
            """
        
        # pandasë¡œ ë¨¼ì € ì½ê³  polarsë¡œ ë³€í™˜
        df_pandas = pd.read_sql_query(query, conn)
        conn.close()
        
        # ì»¬ëŸ¼ëª…ì„ ë¬¸ìì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜
        df_pandas.columns = df_pandas.columns.astype(str)
        
        # ë°ì´í„° íƒ€ì… ì •ë¦¬ (polars í˜¸í™˜ì„±ì„ ìœ„í•´)
        for col in df_pandas.columns:
            col_series = df_pandas[col]
            if isinstance(col_series, pd.DataFrame):
                col_series = col_series.iloc[:, 0]
            if hasattr(col_series, 'dtype'):
                if str(col_series.dtype) in ['Int64', 'int64']:
                    df_pandas[col] = col_series.astype('int64')
                elif str(col_series.dtype) in ['Float64', 'float64']:
                    df_pandas[col] = col_series.astype('float64')
                elif str(col_series.dtype) in ['boolean', 'bool']:
                    df_pandas[col] = col_series.astype('bool')
        
        # polars DataFrameìœ¼ë¡œ ë³€í™˜
        df = pl.from_pandas(df_pandas)
        
        # ë°ì´í„° ë¶„í• 
        total_rows = len(df)
        split_point = int(total_rows * split_ratio)
        
        if use_train_data:
            df = df.head(split_point)
            data_type = "í•™ìŠµìš©"
        else:
            df = df.tail(total_rows - split_point)
            data_type = "í‰ê°€ìš©"
        
        print(f"{data_type} ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} ì»¬ëŸ¼")
        if 'is_answer' in df.columns:
            print(f"is_answer ì»¬ëŸ¼ ë¶„í¬: {df['is_answer'].value_counts().to_dict()}")
        
        return df
        
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

def filter_features_by_config(df, config):
    """
    ì‹¤í—˜ ì„¤ì •ì— ë”°ë¼ íŠ¹ì„±ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    if config['feature_selection']['use_all_features']:
        return df
    
    # íŠ¹ì • íŠ¹ì„±ë§Œ ì„ íƒ
    selected_features = config['feature_selection']['selected_features']
    
    # ì„ íƒëœ íŠ¹ì„±ë“¤ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    available_features = []
    missing_features = []
    
    for feature in selected_features:
        if feature in df.columns:
            available_features.append(feature)
        else:
            missing_features.append(feature)
    
    if missing_features:
        print(f"ê²½ê³ : ë‹¤ìŒ íŠ¹ì„±ë“¤ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_features}")
    
    if not available_features:
        print("ì˜¤ë¥˜: ì„ íƒëœ íŠ¹ì„± ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df
    
    # ì„ íƒëœ íŠ¹ì„±ê³¼ í•„ìˆ˜ ì»¬ëŸ¼ë“¤ë§Œ í¬í•¨
    required_columns = ['date', 'stock_code', 'is_answer'] + available_features
    filtered_df = df.select(required_columns)
    
    print(f"íŠ¹ì„± í•„í„°ë§ ì™„ë£Œ: {len(available_features)}ê°œ íŠ¹ì„± ì‚¬ìš©")
    print(f"ì‚¬ìš©ëœ íŠ¹ì„±: {available_features}")
    
    return filtered_df

def prepare_data_for_model(df, config):
    """
    ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    """
    # íŠ¹ì„± í•„í„°ë§
    df = filter_features_by_config(df, config)
    
    # dateì™€ stock_codeëŠ” ì œì™¸í•˜ê³  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
    numeric_columns = []
    for col in df.columns:
        if col not in ['date', 'stock_code', 'is_answer']:
            if df[col].dtype in [pl.Float64, pl.Float32, pl.Int64, pl.Int32]:
                numeric_columns.append(col)
    
    # is_answer ì»¬ëŸ¼ ì¶”ê°€
    selected_columns = numeric_columns + ['is_answer']
    
    # NaN ê°’ ì²˜ë¦¬
    df_clean = df.select(selected_columns).drop_nulls()
    
    print(f"ì •ë¦¬ëœ ë°ì´í„°: {len(df_clean)} í–‰, {len(df_clean.columns)} ì»¬ëŸ¼")
    
    # polars DataFrameì„ pandasë¡œ ë³€í™˜ (sklearn í˜¸í™˜ì„±ì„ ìœ„í•´)
    df_pandas = df_clean.to_pandas()
    
    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    X = df_pandas.drop('is_answer', axis=1)
    y = df_pandas['is_answer']
    
    print(f"íŠ¹ì„± ìˆ˜: {X.shape[1]}, íƒ€ê²Ÿ ë¶„í¬: {y.value_counts().to_dict()}")
    
    return X, y

def optimize_hyperparameters(X_train, y_train, config):
    """
    í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")
    print(f"ìµœì í™” ê¸°ì¤€: {config['hyperparameter_optimization']['scoring']}")
    print(f"êµì°¨ ê²€ì¦ í´ë“œ: {config['hyperparameter_optimization']['cv_folds']}")
    print(f"ë°˜ë³µ íšŸìˆ˜: {config['hyperparameter_optimization']['n_iter']}")
    
    # ê¸°ë³¸ ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
    base_rf = RandomForestClassifier(
        random_state=config['random_state'],
        n_jobs=-1,
        class_weight=config['class_weight']
    )
    
    # ëœë¤ ì„œì¹˜ ì„¤ì •
    random_search = RandomizedSearchCV(
        estimator=base_rf,
        param_distributions=config['hyperparameter_optimization']['param_distributions'],
        n_iter=config['hyperparameter_optimization']['n_iter'],
        scoring=config['hyperparameter_optimization']['scoring'],
        cv=config['hyperparameter_optimization']['cv_folds'],
        random_state=config['random_state'],
        n_jobs=-1,
        verbose=1
    )
    
    # ìµœì í™” ì‹¤í–‰
    random_search.fit(X_train, y_train)
    
    print(f"ìµœì í™” ì™„ë£Œ!")
    print(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {random_search.best_params_}")
    print(f"ìµœì  ì ìˆ˜: {random_search.best_score_:.4f}")
    
    return random_search.best_estimator_, random_search.best_params_, random_search.best_score_

def train_random_forest(X, y, config):
    """
    ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    """
    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config['test_size'], random_state=config['random_state'], stratify=y
    )
    
    print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]} í–‰, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]} í–‰")
    print(f"í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_train).value_counts().to_dict()}")
    
    # SMOTE ì ìš© ì—¬ë¶€
    if config['use_smote']:
        print("SMOTEë¥¼ ì ìš©í•˜ì—¬ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ í•´ê²°í•©ë‹ˆë‹¤...")
        smote = SMOTE(random_state=config['random_state'], k_neighbors=5)
        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
        print(f"SMOTE ì ìš© í›„ í›ˆë ¨ ë°ì´í„°: {X_train_resampled.shape[0]} í–‰")
        print(f"SMOTE ì ìš© í›„ í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_train_resampled).value_counts().to_dict()}")
    else:
        X_train_resampled, y_train_resampled = X_train, y_train
        print("SMOTEë¥¼ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—¬ë¶€ í™•ì¸
    if config['hyperparameter_optimization']['enabled']:
        print("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        rf_model, best_params, best_score = optimize_hyperparameters(X_train_resampled, y_train_resampled, config)
        print(f"ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ìµœì  ì ìˆ˜: {best_score:.4f})")
    else:
        print("ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤...")
        # ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        rf_model = RandomForestClassifier(
            n_estimators=config['n_estimators'],
            max_depth=config['max_depth'],
            min_samples_split=config['min_samples_split'],
            min_samples_leaf=config['min_samples_leaf'],
            random_state=config['random_state'],
            n_jobs=-1,
            class_weight=config['class_weight']
        )
        
        print("ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        rf_model.fit(X_train_resampled, y_train_resampled)
    
    return rf_model, X_test, y_test

def evaluate_model(model, X_test, y_test):
    """
    ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
    """
    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_test, y_pred)
    
    # ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
    report = classification_report(y_test, y_pred, output_dict=True)
    
    # êµì°¨ ê²€ì¦
    cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'confusion_matrix': cm.tolist(),
        'classification_report': report,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'total_samples': len(y_test),
        'positive_samples': sum(y_test == 1),
        'negative_samples': sum(y_test == 0)
    }
    
    return metrics

def print_evaluation_results(metrics, model_name, eval_type="ê¸°ë³¸"):
    """
    í‰ê°€ ê²°ê³¼ë¥¼ ê°„ëµí•˜ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print(f"\n{'='*50}")
    print(f"[{model_name}] {eval_type} í‰ê°€")
    print(f"{'='*50}")
    
    print(f"ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
    print(f"   ì •í™•ë„: {metrics['accuracy']:.4f} | ì •ë°€ë„: {metrics['precision']:.4f} | ì¬í˜„ìœ¨: {metrics['recall']:.4f} | F1: {metrics['f1_score']:.4f}")
    
    print(f"ğŸ“ˆ ë°ì´í„° í˜„í™©:")
    print(f"   ì´ ìƒ˜í”Œ: {metrics['total_samples']:,} | ê¸‰ë“±: {metrics['positive_samples']:,} | ë¹„ê¸‰ë“±: {metrics['negative_samples']:,} | ê¸‰ë“±ë¹„ìœ¨: {metrics['positive_samples']/metrics['total_samples']*100:.1f}%")
    
    # í˜¼ë™ í–‰ë ¬ ê°„ëµí™”
    cm = metrics['confusion_matrix']
    print(f"ğŸ¯ í˜¼ë™í–‰ë ¬: TN={cm[0][0]:,} | FP={cm[0][1]:,} | FN={cm[1][0]:,} | TP={cm[1][1]:,}")

def predict_and_evaluate_on_test_data(model, day_types, config):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì˜ˆì¸¡ ë° í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    df_test = load_data_from_db(day_types, config['db_path'], config['split_ratio'], use_train_data=False)
    if df_test is None:
        return None
    
    # ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„
    X_test_full, y_test_full = prepare_data_for_model(df_test, config)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(X_test_full)
    y_pred_proba = model.predict_proba(X_test_full)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = evaluate_model(model, X_test_full, y_test_full)
    
    return metrics, y_pred, y_pred_proba, df_test

def predict_top_per_day(model, day_types, config):
    """
    í•˜ë£¨ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ì¢…ëª©ë§Œ ì„ íƒí•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    df_test = load_data_from_db(day_types, config['db_path'], config['split_ratio'], use_train_data=False)
    if df_test is None:
        return None
    
    # ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„
    X_test_full, y_test_full = prepare_data_for_model(df_test, config)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(X_test_full)
    y_pred_proba = model.predict_proba(X_test_full)
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    result_df = df_test.select(['date', 'stock_code']).to_pandas()
    result_df['predicted_class'] = y_pred
    result_df['predicted_proba_0'] = y_pred_proba[:, 0]
    result_df['predicted_proba_1'] = y_pred_proba[:, 1]
    result_df['actual_class'] = df_test.select('is_answer').to_pandas()
    
    # í•˜ë£¨ ê¸°ì¤€ìœ¼ë¡œ ê¸‰ë“± í™•ë¥ ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œ ì„ íƒ
    result_df = result_df.sort_values(['date', 'predicted_proba_1'], ascending=[True, False])
    
    # ê° ë‚ ì§œë³„ë¡œ ìƒìœ„ kê°œ ì„ íƒ
    top_stocks = []
    for date in result_df['date'].unique():
        day_data = result_df[result_df['date'] == date]
        top_day_stocks = day_data.head(config['top_k'])
        top_stocks.append(top_day_stocks)
    
    top_result_df = pd.concat(top_stocks, ignore_index=True)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (ì´ë¯¸ ì˜ˆì¸¡ëœ ê²°ê³¼ë¥¼ ì‚¬ìš©)
    y_pred_top = top_result_df['predicted_class'].values
    y_actual_top = top_result_df['actual_class'].values
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_actual_top, y_pred_top)
    precision = precision_score(y_actual_top, y_pred_top, zero_division=0)
    recall = recall_score(y_actual_top, y_pred_top, zero_division=0)
    f1 = f1_score(y_actual_top, y_pred_top, zero_division=0)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_actual_top, y_pred_top)
    
    # ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
    report = classification_report(y_actual_top, y_pred_top, output_dict=True)
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'confusion_matrix': cm.tolist(),
        'classification_report': report,
        'cv_mean': accuracy,  # Top-kì˜ ê²½ìš° êµì°¨ê²€ì¦ ì˜ë¯¸ ì—†ìŒ
        'cv_std': 0.0,
        'total_samples': len(y_actual_top),
        'positive_samples': sum(y_actual_top == 1),
        'negative_samples': sum(y_actual_top == 0)
    }
    
    return metrics, top_result_df

def print_top_per_day_results(metrics, model_name, top_k, result_df):
    """
    Top-k per day ê²°ê³¼ë¥¼ ê°„ëµí•˜ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print(f"\n{'='*50}")
    print(f"[{model_name}] Top-{top_k} per Day í‰ê°€")
    print(f"{'='*50}")
    
    # ë‚ ì§œ ë²”ìœ„ ì¶œë ¥
    start_date = result_df['date'].min()
    end_date = result_df['date'].max()
    print(f"ğŸ“… í‰ê°€ ê¸°ê°„: {start_date} ~ {end_date} ({result_df['date'].nunique()}ì¼)")
    print(f"ğŸ“Š ì„ íƒ ì¢…ëª©: {len(result_df):,}ê°œ")
    
    print(f"ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"   ì •í™•ë„: {metrics['accuracy']:.4f} | ì •ë°€ë„: {metrics['precision']:.4f} | ì¬í˜„ìœ¨: {metrics['recall']:.4f} | F1: {metrics['f1_score']:.4f}")
    
    print(f"ğŸ“Š ë°ì´í„° í˜„í™©:")
    print(f"   ì´ ìƒ˜í”Œ: {metrics['total_samples']:,} | ê¸‰ë“±: {metrics['positive_samples']:,} | ë¹„ê¸‰ë“±: {metrics['negative_samples']:,} | ê¸‰ë“±ë¹„ìœ¨: {metrics['positive_samples']/metrics['total_samples']*100:.1f}%")
    
    # í˜¼ë™ í–‰ë ¬ ê°„ëµí™”
    cm = metrics['confusion_matrix']
    print(f"ğŸ¯ í˜¼ë™í–‰ë ¬: TN={cm[0][0]:,} | FP={cm[0][1]:,} | FN={cm[1][0]:,} | TP={cm[1][1]:,}")
    
    # í™•ë¥  ë¶„í¬ ì‹œê°í™”
    plot_probability_distribution(result_df, model_name, top_k)

def perform_shap_analysis(model, X_train, X_test, feature_names, model_name, config):
    """
    SHAP ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    print(f"\nğŸ” SHAP ë¶„ì„ ì‹œì‘: {model_name}")
    
    # SHAP Explainer ìƒì„± (TreeExplainer for Random Forest)
    explainer = shap.TreeExplainer(model)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ SHAP ê°’ ê³„ì‚° (ìƒ˜í”Œë§í•˜ì—¬ ì†ë„ í–¥ìƒ)
    sample_size = min(1000, len(X_test))
    X_test_sample = X_test.sample(n=sample_size, random_state=config['random_state'])
    
    print(f"SHAP ê°’ ê³„ì‚° ì¤‘... (ìƒ˜í”Œ í¬ê¸°: {sample_size})")
    shap_values = explainer.shap_values(X_test_sample)
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    results_dir = Path("results/shap_analysis")
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. íŠ¹ì„± ì¤‘ìš”ë„ ìš”ì•½ í”Œë¡¯
    plt.figure(figsize=(12, 8))
    shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, 
                     show=False, plot_type="bar")
    plt.title(f'{model_name} - SHAP íŠ¹ì„± ì¤‘ìš”ë„')
    plt.tight_layout()
    plt.savefig(results_dir / f'{model_name}_shap_summary_bar.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 2. SHAP ìš”ì•½ í”Œë¡¯ (ì  í”Œë¡¯)
    plt.figure(figsize=(12, 10))
    shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, show=False)
    plt.title(f'{model_name} - SHAP ìš”ì•½ í”Œë¡¯')
    plt.tight_layout()
    plt.savefig(results_dir / f'{model_name}_shap_summary_dots.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 3. ìƒìœ„ 10ê°œ íŠ¹ì„±ì— ëŒ€í•œ ê°œë³„ SHAP í”Œë¡¯
    feature_importance = np.abs(shap_values).mean(0)
    top_features_idx = np.argsort(feature_importance)[-10:]
    top_features = [feature_names[i] for i in top_features_idx]
    
    print(f"ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±: {top_features}")
    
    # 4. ì˜ì¡´ì„± í”Œë¡¯ (ìƒìœ„ 5ê°œ íŠ¹ì„±)
    for i, feature_idx in enumerate(top_features_idx[-5:]):
        feature_name = feature_names[feature_idx]
        plt.figure(figsize=(10, 6))
        shap.dependence_plot(feature_idx, shap_values, X_test_sample, 
                           feature_names=feature_names, show=False)
        plt.title(f'{model_name} - {feature_name} ì˜ì¡´ì„± í”Œë¡¯')
        plt.tight_layout()
        plt.savefig(results_dir / f'{model_name}_shap_dependence_{feature_name}.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
    
    # 5. íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì €ì¥
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance
    }).sort_values('importance', ascending=False)
    
    importance_df.to_csv(results_dir / f'{model_name}_feature_importance.csv', index=False)
    
    # 6. ìƒìœ„ íŠ¹ì„±ë“¤ì˜ SHAP ê°’ ë¶„í¬
    plt.figure(figsize=(15, 10))
    for i, feature_idx in enumerate(top_features_idx[-6:]):
        plt.subplot(2, 3, i+1)
        feature_name = feature_names[feature_idx]
        shap.dependence_plot(feature_idx, shap_values, X_test_sample, 
                           feature_names=feature_names, show=False)
        plt.title(f'{feature_name}')
        plt.xlabel('')
        plt.ylabel('')
    
    plt.suptitle(f'{model_name} - ìƒìœ„ 6ê°œ íŠ¹ì„± SHAP ì˜ì¡´ì„±')
    plt.tight_layout()
    plt.savefig(results_dir / f'{model_name}_shap_top_features.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 7. SHAP ê°’ í†µê³„ ì •ë³´ ì¶œë ¥
    print(f"\nğŸ“Š SHAP ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
    print(f"   - ë¶„ì„ëœ ìƒ˜í”Œ ìˆ˜: {sample_size}")
    print(f"   - íŠ¹ì„± ìˆ˜: {len(feature_names)}")
    print(f"   - ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:")
    for i, (feature, importance) in enumerate(importance_df.head().values):
        print(f"     {i+1}. {feature}: {importance:.4f}")
    
    return {
        'explainer': explainer,
        'shap_values': shap_values,
        'feature_importance': importance_df,
        'top_features': top_features
    }

def plot_probability_distribution(result_df, model_name, top_k):
    """
    ì„ ì •ëœ ì¢…ëª©ë“¤ì˜ ê¸‰ë“± í™•ë¥ ì„ ì‹¤ì œ ê¸‰ë“±/ë¹„ê¸‰ë“±ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    # ì²« ë²ˆì§¸ ê·¸ë˜í”„: í™•ë¥  ë¶„í¬
    plt.figure(figsize=(15, 10))
    
    # ì‹¤ì œ ê¸‰ë“±/ë¹„ê¸‰ë“±ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬
    actual_positive = result_df[result_df['actual_class'] == 1]['predicted_proba_1']
    actual_negative = result_df[result_df['actual_class'] == 0]['predicted_proba_1']
    
    # ë°•ìŠ¤í”Œë¡¯ ê·¸ë¦¬ê¸°
    plt.subplot(2, 3, 1)
    data_to_plot = [actual_negative, actual_positive]
    labels = ['ì‹¤ì œ ë¹„ê¸‰ë“±', 'ì‹¤ì œ ê¸‰ë“±']
    colors = ['lightcoral', 'lightgreen']
    
    bp = plt.boxplot(data_to_plot, labels=labels, patch_artist=True)
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
    
    plt.title(f'{model_name} Top-{top_k} ê¸‰ë“± í™•ë¥  ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)')
    plt.ylabel('ê¸‰ë“± í™•ë¥ ')
    plt.grid(True, alpha=0.3)
    
    # íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸° (ê°œìˆ˜ ê¸°ì¤€)
    plt.subplot(2, 3, 2)
    plt.hist(actual_negative, bins=20, alpha=0.7, label='ì‹¤ì œ ë¹„ê¸‰ë“±', color='lightcoral', density=False)
    plt.hist(actual_positive, bins=20, alpha=0.7, label='ì‹¤ì œ ê¸‰ë“±', color='lightgreen', density=False)
    plt.title(f'{model_name} Top-{top_k} ê¸‰ë“± í™•ë¥  ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)')
    plt.xlabel('ê¸‰ë“± í™•ë¥ ')
    plt.ylabel('ê°œìˆ˜')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ë°”ì´ì˜¬ë¦° í”Œë¡¯ ê·¸ë¦¬ê¸°
    plt.subplot(2, 3, 3)
    from matplotlib.patches import Rectangle
    
    # ë°”ì´ì˜¬ë¦° í”Œë¡¯ ë°ì´í„° ì¤€ë¹„
    violin_data = [actual_negative, actual_positive]
    violin_parts = plt.violinplot(violin_data, positions=[1, 2], showmeans=True)
    
    # ë°”ì´ì˜¬ë¦° í”Œë¡¯ ìƒ‰ìƒ ì„¤ì •
    for i, pc in enumerate(violin_parts['bodies']):
        if i == 0:
            pc.set_facecolor('lightcoral')
            pc.set_alpha(0.7)
        else:
            pc.set_facecolor('lightgreen')
            pc.set_alpha(0.7)
    
    plt.xticks([1, 2], ['ì‹¤ì œ ë¹„ê¸‰ë“±', 'ì‹¤ì œ ê¸‰ë“±'])
    plt.title(f'{model_name} Top-{top_k} ê¸‰ë“± í™•ë¥  ë¶„í¬ (ë°”ì´ì˜¬ë¦° í”Œë¡¯)')
    plt.ylabel('ê¸‰ë“± í™•ë¥ ')
    plt.grid(True, alpha=0.3)
    
    # PR Curve ê·¸ë¦¬ê¸°
    plt.subplot(2, 3, 4)
    from sklearn.metrics import precision_recall_curve
    
    y_true = result_df['actual_class'].values
    y_scores = result_df['predicted_proba_1'].values
    
    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
    
    plt.plot(recall, precision, 'b-', linewidth=2, label=f'PR Curve')
    plt.fill_between(recall, precision, alpha=0.3, color='blue')
    
    # ëœë¤ ë¶„ë¥˜ê¸° ê¸°ì¤€ì„ 
    no_skill = len(y_true[y_true == 1]) / len(y_true)
    plt.axhline(y=no_skill, color='red', linestyle='--', label=f'Random Classifier ({no_skill:.3f})')
    
    plt.xlabel('ì¬í˜„ìœ¨ (Recall)')
    plt.ylabel('ì •ë°€ë„ (Precision)')
    plt.title(f'{model_name} Top-{top_k} PR Curve')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Precision vs Threshold ê·¸ë˜í”„
    plt.subplot(2, 3, 5)
    
    # ì„ê³„ê°’ë³„ ì •ë°€ë„ ê³„ì‚°
    threshold_range = np.arange(0.1, 1.0, 0.05)
    precision_at_threshold = []
    recall_at_threshold = []
    
    for threshold in threshold_range:
        y_pred_threshold = (y_scores >= threshold).astype(int)
        if sum(y_pred_threshold) > 0:
            precision_at_threshold.append(precision_score(y_true, y_pred_threshold, zero_division=0))
            recall_at_threshold.append(recall_score(y_true, y_pred_threshold, zero_division=0))
        else:
            precision_at_threshold.append(0)
            recall_at_threshold.append(0)
    
    plt.plot(threshold_range, precision_at_threshold, 'g-', linewidth=2, label='ì •ë°€ë„ (Precision)')
    plt.plot(threshold_range, recall_at_threshold, 'r-', linewidth=2, label='ì¬í˜„ìœ¨ (Recall)')
    plt.xlabel('ì„ê³„ê°’ (Threshold)')
    plt.ylabel('ì ìˆ˜')
    plt.title(f'{model_name} Top-{top_k} Precision/Recall vs Threshold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # í†µê³„ ì •ë³´ í‘œì‹œ
    plt.subplot(2, 3, 6)
    plt.axis('off')
    
    # í†µê³„ ì •ë³´ ê³„ì‚°
    pos_mean = actual_positive.mean()
    pos_std = actual_positive.std()
    pos_median = actual_positive.median()
    neg_mean = actual_negative.mean()
    neg_std = actual_negative.std()
    neg_median = actual_negative.median()
    
    # PR Curve AUC ê³„ì‚°
    from sklearn.metrics import auc
    pr_auc = auc(recall, precision)
    
    stats_text = f"""
    í†µê³„ ì •ë³´:
    
    ì‹¤ì œ ê¸‰ë“± ì¢…ëª©:
    - í‰ê· : {pos_mean:.4f}
    - í‘œì¤€í¸ì°¨: {pos_std:.4f}
    - ì¤‘ì•™ê°’: {pos_median:.4f}
    - ê°œìˆ˜: {len(actual_positive)}
    
    ì‹¤ì œ ë¹„ê¸‰ë“± ì¢…ëª©:
    - í‰ê· : {neg_mean:.4f}
    - í‘œì¤€í¸ì°¨: {neg_std:.4f}
    - ì¤‘ì•™ê°’: {neg_median:.4f}
    - ê°œìˆ˜: {len(actual_negative)}
    
    í™•ë¥  ì°¨ì´:
    - í‰ê·  ì°¨ì´: {pos_mean - neg_mean:.4f}
    - ì¤‘ì•™ê°’ ì°¨ì´: {pos_median - neg_median:.4f}
    
    PR Curve AUC: {pr_auc:.4f}
    """
    
    plt.text(0.1, 0.9, stats_text, transform=plt.gca().transAxes, 
             fontsize=9, verticalalignment='top', fontfamily=plt.rcParams['font.family'],
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
    
    plt.tight_layout()
    plt.show()
    
    # ì¶”ê°€ë¡œ í™•ë¥  êµ¬ê°„ë³„ ë¶„ì„
    print(f"\n{'='*40}")
    print("í™•ë¥  êµ¬ê°„ë³„ ë¶„ì„")
    print(f"{'='*40}")
    
    # í™•ë¥  êµ¬ê°„ ì„¤ì •
    prob_ranges = [(0.0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1.0)]
    
    for low, high in prob_ranges:
        range_data = result_df[(result_df['predicted_proba_1'] >= low) & (result_df['predicted_proba_1'] < high)]
        if len(range_data) > 0:
            pos_count = sum(range_data['actual_class'] == 1)
            neg_count = sum(range_data['actual_class'] == 0)
            total_count = len(range_data)
            pos_rate = pos_count / total_count * 100 if total_count > 0 else 0
            
            print(f"í™•ë¥  {low:.1f}-{high:.1f}: {total_count}ê°œ ì¢…ëª©")
            print(f"  - ì‹¤ì œ ê¸‰ë“±: {pos_count}ê°œ ({pos_rate:.1f}%)")
            print(f"  - ì‹¤ì œ ë¹„ê¸‰ë“±: {neg_count}ê°œ ({100-pos_rate:.1f}%)")
    
    # ìµœê³  í™•ë¥  êµ¬ê°„ ë¶„ì„
    high_prob_data = result_df[result_df['predicted_proba_1'] >= 0.8]
    if len(high_prob_data) > 0:
        print(f"\në†’ì€ í™•ë¥  (â‰¥0.8) ì¢…ëª© ë¶„ì„:")
        print(f"  - ì´ ê°œìˆ˜: {len(high_prob_data)}")
        print(f"  - ì‹¤ì œ ê¸‰ë“±: {sum(high_prob_data['actual_class'] == 1)}ê°œ")
        print(f"  - ì‹¤ì œ ë¹„ê¸‰ë“±: {sum(high_prob_data['actual_class'] == 0)}ê°œ")
        print(f"  - ê¸‰ë“± ë¹„ìœ¨: {sum(high_prob_data['actual_class'] == 1)/len(high_prob_data)*100:.1f}%")

def run_single_experiment(day_types, config):
    """
    ë‹¨ì¼ ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    if isinstance(day_types, str):
        day_types = [day_types]
    
    model_name = "_".join(day_types)
    print(f"\n{'='*60}")
    print(f"ğŸš€ {model_name.upper()} ì‹¤í—˜ ì‹œì‘")
    print(f"{'='*60}")
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ
    print("\nğŸ“¥ 1. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ")
    df_train = load_data_from_db(day_types, config['db_path'], config['split_ratio'], use_train_data=True)
    if df_train is None:
        print(f"âŒ {model_name} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return None
    
    X_train, y_train = prepare_data_for_model(df_train, config)
    model, X_test, y_test = train_random_forest(X_train, y_train, config)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ì €ì¥
    optimization_info = None
    if config['hyperparameter_optimization']['enabled']:
        # ìµœì í™”ëœ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥
        optimization_info = {
            'scoring': config['hyperparameter_optimization']['scoring'],
            'cv_folds': config['hyperparameter_optimization']['cv_folds'],
            'n_iter': config['hyperparameter_optimization']['n_iter'],
            'best_params': model.get_params()
        }
    
    # 2. ê¸°ë³¸ í‰ê°€ (í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• )
    print("\nğŸ“Š 2. ê¸°ë³¸ í‰ê°€ (í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• )")
    basic_metrics = evaluate_model(model, X_test, y_test)
    print_evaluation_results(basic_metrics, model_name, "ê¸°ë³¸")
    
    # 3. ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í‰ê°€
    print("\nğŸ” 3. ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í‰ê°€")
    test_metrics, y_pred, y_pred_proba, df_test = predict_and_evaluate_on_test_data(model, day_types, config)
    if test_metrics:
        print_evaluation_results(test_metrics, model_name, "ì „ì²´ í…ŒìŠ¤íŠ¸")
    
    # 4. Top-k per day í‰ê°€
    print(f"\nğŸ¯ 4. Top-{config['top_k']} per day í‰ê°€")
    top_metrics, top_result_df = predict_top_per_day(model, day_types, config)
    if top_metrics:
        print_top_per_day_results(top_metrics, model_name, config['top_k'], top_result_df)
    
    # 5. SHAP ë¶„ì„
    print(f"\nğŸ” 5. SHAP ë¶„ì„")
    shap_results = perform_shap_analysis(model, X_train, X_test, list(X_train.columns), model_name, config)
    
    return {
        'model_name': model_name,
        'basic_metrics': basic_metrics,
        'test_metrics': test_metrics,
        'top_metrics': top_metrics,
        'shap_results': shap_results,
        'model': model,
        'feature_names': list(X_train.columns),
        'optimization_info': optimization_info
    }

def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ì„¤ì •ëœ ëª¨ë“  ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("="*80)
    print("í†µí•© ì‹¤í—˜ ì‹œì‘")
    print("="*80)
    print(f"ì‹¤í—˜ ì„¤ì •:")
    print(f"  - ë°ì´í„°ë² ì´ìŠ¤: {EXPERIMENT_CONFIG['db_path']}")
    print(f"  - SMOTE ì‚¬ìš©: {EXPERIMENT_CONFIG['use_smote']}")
    print(f"  - Top-k: {EXPERIMENT_CONFIG['top_k']}")
    print(f"  - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: {EXPERIMENT_CONFIG['hyperparameter_optimization']['enabled']}")
    if EXPERIMENT_CONFIG['hyperparameter_optimization']['enabled']:
        print(f"    - ìµœì í™” ê¸°ì¤€: {EXPERIMENT_CONFIG['hyperparameter_optimization']['scoring']}")
        print(f"    - êµì°¨ ê²€ì¦ í´ë“œ: {EXPERIMENT_CONFIG['hyperparameter_optimization']['cv_folds']}")
        print(f"    - ë°˜ë³µ íšŸìˆ˜: {EXPERIMENT_CONFIG['hyperparameter_optimization']['n_iter']}")
    print(f"  - ì‹¤í—˜ ì¡°í•©: {list(EXPERIMENT_CONFIG['experiments'].keys())}")
    
    # ì‹¤í—˜í•  ëª¨ë¸ ì¡°í•©ë“¤
    model_combinations = {
        'day1': ['day1'],
        'day2': ['day2'],
        'day3': ['day3'],
        'day4': ['day4'],
        'day1_day2_day3': ['day1', 'day2', 'day3'],
        'day1_day2_day3_day4': ['day1', 'day2', 'day3', 'day4']
    }
    
    all_results = {}
    
    # ê° ì‹¤í—˜ ì¡°í•©ì— ëŒ€í•´ ì‹¤í–‰
    for exp_name, enabled in EXPERIMENT_CONFIG['experiments'].items():
        if enabled and exp_name in model_combinations:
            try:
                result = run_single_experiment(model_combinations[exp_name], EXPERIMENT_CONFIG)
                if result is not None:
                    all_results[exp_name] = result
            except Exception as e:
                print(f"{exp_name} ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
    
    # ì „ì²´ ìš”ì•½
    print(f"\n{'='*80}")
    print("ğŸ¯ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")
    
    for exp_name, result in all_results.items():
        print(f"\nğŸ“Š {exp_name.upper()} ëª¨ë¸:")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì •ë³´
        if result['optimization_info']:
            print(f"   ğŸ”§ ìµœì í™”: {result['optimization_info']['scoring']} ê¸°ì¤€")
        
        # ì„±ëŠ¥ ì§€í‘œ ìš”ì•½
        metrics_summary = []
        if result['basic_metrics']:
            metrics_summary.append(f"ê¸°ë³¸ F1: {result['basic_metrics']['f1_score']:.3f}")
        if result['test_metrics']:
            metrics_summary.append(f"í…ŒìŠ¤íŠ¸ F1: {result['test_metrics']['f1_score']:.3f}")
        if result['top_metrics']:
            metrics_summary.append(f"Top-{EXPERIMENT_CONFIG['top_k']} F1: {result['top_metrics']['f1_score']:.3f}")
        
        print(f"   ğŸ“ˆ ì„±ëŠ¥: {' | '.join(metrics_summary)}")
        print(f"   ğŸ” íŠ¹ì„±: {len(result['feature_names'])}ê°œ")
        
        # SHAP ë¶„ì„ ê²°ê³¼ ìš”ì•½
        if result['shap_results']:
            top_features = result['shap_results']['top_features'][:3]  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
            print(f"   ğŸ¯ SHAP ìƒìœ„ íŠ¹ì„±: {', '.join(top_features)}")

if __name__ == "__main__":
    main() 